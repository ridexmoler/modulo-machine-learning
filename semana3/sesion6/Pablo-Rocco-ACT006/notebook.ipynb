{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='logo.png' style='display: block;height: 61px;float: left;padding: .75rem 1.25rem;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafío - Inferencia de tópicos con EM\n",
    "* Para realizar este desafío debes haber revisado la lectura y videos correspondiente a la unidad.\n",
    "* Crea una carpeta de trabajo y guarda todos los archivos correspondientes (notebook y csv).\n",
    "* Una vez terminado el desafío, comprime la carpeta y sube el `.zip` a la seccióncorrespondiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción\n",
    "\n",
    "* En esta sesión trabajaremos con una serie de base de datos sobre letras musicales de distintos artistas. Cada uno de los `csv` se encuentra en la carpeta `dump`.\n",
    "* Cada `csv` tiene el nombre del artista a analizar. Los archivos contienen el nombre del artista, elgénero musical del artista, el nombre de la canción y las letras.\n",
    "* En base a esta información, el objetivo del ejercicio es generar un modelo probabilístico quepueda identificar el género musical más probable dado la letra de una canción.\n",
    "* Para ello implementaremos un modelo conocido como Latent Dirichlet Allocation que hace uso de una variante del algoritmo EM para inferir clases latentes a partir de una matriz dedocumentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Preparar el ambiente de trabajo\n",
    "\n",
    "* Importe los módulos `numpy`, `pandas`, `matplotlib`, `seaborn`, `glob` y `os` siguiendo las buenas prácticas. Los últimos dos módulos permitirán realizar la importación de múltiplesarchivos dentro de la carpeta dump.\n",
    "* Para ello genere un objeto que guarde en una lista todos los archivos alojados en dumputilizando `glob.glob` y `os.getcwd()` para extraer las rutas absolutas. Posteriormente genere un objeto `pd.DataFrame` que contenga todos los csv.\n",
    "* Asegúrese de eliminar la columna `Unnamed: 0` que se genera por defecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Se utilizan librerías bases para el tratamiento de datos y algunos aspectos básicos de cálculo y gráficos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importa libreria para el manejo de bases de datos\n",
    "import pandas as pd\n",
    "# Se importa libreria para el manejo de operaciones de cálculo\n",
    "import numpy as np\n",
    "# Se importa libreria para el manejo de gráficos\n",
    "import matplotlib.pyplot as plt\n",
    "# Se importa libreria para manejo de funciones estadisticas y probabilidades\n",
    "import seaborn as sns\n",
    "# Librería para visualizar patrones de datos perdidos\n",
    "import missingno as msngo\n",
    "# Se importa libreria para el menejo de warning\n",
    "import warnings\n",
    "# Se importa libreria para el menejo de expresiones regulares\n",
    "import glob, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Definimos algunos aspectos de ambiente y valores por defecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por defecto, matplotlib crea una figura en una ventana separada.\n",
    "# podemos hacer que las figuras aparezcan en línea dentro del notebook; lo hacemos ejecutando:\n",
    "%matplotlib inline\n",
    "# Se ignoran los warning para evitar suciedad en la ejecución\n",
    "warnings.filterwarnings(action='ignore')\n",
    "# Se define el estilo de gráficos a usar\n",
    "plt.style.use('seaborn-pastel')\n",
    "# Se define el tamaño de los paños de los gráficos por defecto\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "# Dado que vamos a supervisar datos no limitaremos la cantidad de columnas a mostrar en el despliegue del dataframe\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Se utiliza <strong>librería propia</strong> que continen funciones auxiliares, necesarias para el desarrollo de desafíos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importa libreria con funciones auxiliares\n",
    "import ancilliary_funcs as afx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Se utilizan librerías <strong>sklearn</strong> para el tratamiento de escala de valores de los atributos y seleccion de set de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método para contar palabras y vectorizar\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Carga de nuestra base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos el listado de archivos con su path con la librería glob y lo\n",
    "# almacenamos en la lista file_list\n",
    "file_list = glob.glob(os.getcwd() + '/dump/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciamos una lista vacia para cargar el contenido de cada archivo csv\n",
    "append_csv = []\n",
    "# Recorremos el listado de archivos, lo cargamos en memoria con read_csv y\n",
    "# lo agregamos a la lista appappend_csv\n",
    "for filename in file_list:\n",
    "    append_csv.append(pd.read_csv(filename, index_col=None, header=0)\n",
    "                      .drop(columns = 'Unnamed: 0')\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se concatenan todos los objetos DataFrames almacenados en la lista append_csv en 1 solo DataFrame\n",
    "df = pd.concat(append_csv)\n",
    "# Se asigna un nombre a cada columna del DataFrame\n",
    "df.columns = ['Artis', 'Genre', 'Song', 'Lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artis</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Song</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Kiss</td>\n",
       "      <td>rock</td>\n",
       "      <td>When Lightning Strikes</td>\n",
       "      <td>Alright \\n It's my move, the ground's shakin' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>Eminem</td>\n",
       "      <td>hiphop</td>\n",
       "      <td>Rap Name - (Obie Trice)</td>\n",
       "      <td>The rap game hip hop 101 the hardest 9 to 5 yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>The Doors</td>\n",
       "      <td>rock</td>\n",
       "      <td>Celebration Of The Lizard (An Experiment/Work ...</td>\n",
       "      <td>Lions in the street and roaming \\n Dogs in hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Iron Maiden</td>\n",
       "      <td>metal</td>\n",
       "      <td>The Prophecy</td>\n",
       "      <td>Now that I know that the right time has come \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>The Beatles</td>\n",
       "      <td>rock</td>\n",
       "      <td>Sgt. Pepper's Lonely Hearts Club Band</td>\n",
       "      <td>It was twenty years ago today \\n That Sgt. Pep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Artis   Genre                                               Song  \\\n",
       "204         Kiss    rock                             When Lightning Strikes   \n",
       "417       Eminem  hiphop                            Rap Name - (Obie Trice)   \n",
       "39     The Doors    rock  Celebration Of The Lizard (An Experiment/Work ...   \n",
       "70   Iron Maiden   metal                                       The Prophecy   \n",
       "97   The Beatles    rock              Sgt. Pepper's Lonely Hearts Club Band   \n",
       "\n",
       "                                                Lyrics  \n",
       "204  Alright \\n It's my move, the ground's shakin' ...  \n",
       "417  The rap game hip hop 101 the hardest 9 to 5 yo...  \n",
       "39   Lions in the street and roaming \\n Dogs in hea...  \n",
       "70   Now that I know that the right time has come \\...  \n",
       "97   It was twenty years ago today \\n That Sgt. Pep...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspeccionamos los datos\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9489, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos las dimensiones de la base de datos\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> La base de datos se compone de 9489 observaciones con 4 atributos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Matriz de ocurrencias\n",
    "\n",
    "* Importe la clase `CountVectorizer` dentro de los módulos `feature_extraction.text` de lalibrería `sklearn`.\n",
    "* Aplique la clase para extraer las 5000 palabras más repetidas en toda la base de datos.\n",
    "* Con la clase inicializada, incorpore las letras con el método `fit_transform` y guarde los resultados en un nuevo objeto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Convertimos los textos en vectores de recuento de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_vectorizer_fit = count_vectorizer.fit_transform(df['Lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = count_vectorizer.get_feature_names()\n",
    "words_count = count_vectorizer_fit.toarray().sum(axis=0)\n",
    "df_words = pd.DataFrame({'word': words, 'count': words_count})\n",
    "df_words_5000 = df_words.sort_values(by='count', ascending=False).head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words_5000.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Entrenamiento del Modelo\n",
    "\n",
    "* Importe `sklearn.decomposition.LatentDirichletAllocatin` y `sklearn.model_selection.GridSearchCV`.\n",
    "* Genere una búsqueda de grilla con los siguientes hiperparámetros:\n",
    "  - n_components: [5, 10, 15].\n",
    "  - learning_decay: [0.7, 0.5].\n",
    "* Entrene la búsqueda de grilla con las letras en un formato vectorizado con CountVectorizer.\n",
    "* Reporte brevemente cuál es la mejor combinación de hiperparámetros.\n",
    "\n",
    "> Digresión: Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
